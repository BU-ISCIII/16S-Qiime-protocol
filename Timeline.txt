
##################################################
4-5-2021
URL de descarga de los datos brutos: https://drive.google.com/file/d/12VtoxKX92ZnjHBi2qY6JlwzoU3B3Je8M/view?usp=sharing_eil&ts=60910b66
Lecturas: metagenéticas 16S, paired-end
##################################################

# Samplesheet
muestra N_lecturas  FilenameR1  FilenameR2
G-bloqu2-bloq   189679.19   G-bloqu2-bloq_S107_L001_R1_001.fastq.gz G-bloqu2-bloq_S107_L001_R2_001.fastq.gz
P-bloqu2-bloq   163328.746  P-bloqu2-bloq_S108_L001_R1_001.fastq.gz P-bloqu2-bloq_S108_L001_R2_001.fastq.gz
R-bloqu2-bloq   161898.45   R-bloqu2-bloq_S109_L001_R1_001.fastq.gz R-bloqu2-bloq_S109_L001_R2_001.fastq.gz 
G-bloqu2-nobloq 75072.1775  G-bloqu2-nobloq_S104_L001_R1_001.fastq.gz   G-bloqu2-nobloq_S104_L001_R2_001.fastq.gz
P-bloqu2-nobloq 107162.141  P-bloqu2-nobloq_S105_L001_R1_001.fastq.gz   P-bloqu2-nobloq_S105_L001_R2_001.fastq.gz
R-bloqu2-nobloq 136959.964  R-bloqu2-nobloq_S106_L001_R1_001.fastq.gz   R-bloqu2-nobloq_S106_L001_R2_001.fastq.gz

# Metadata

1. Se organizan en directorios con el nombre de muestra
    1.1 Se genera un script para organizarlos y evitar la organización manual
    NOTA 5-5-2021: se genera el script Sample_catalog.py, que hace esto mismo

2. Se genera environment inicialmente con fastqc para control de calidad:

    conda create --name bloqueadores_control_calidad fastqc
    conda activate bloqueadores_control_calidad
    conda install -c anaconda python=3.7
    conda install fastp

3. Se genera el script fastqc_directories_trim_fastq.sh para un control de calidad de todas las muestras,
un trimming y otro fastqc, seguido de la elaboración del manifest para qiime.
    Tarea realizada el 5-5-2021, resultados junto a muestras.

4. Se genera nuevo environment para lanzar qiime (incompatibilidad con fastqc)

    conda create --name bloqueadores_qiime qiime
    conda activate bloqueadores_qiime

    NOTA: Eso era la teoría, 

5. Se genera la pipeline para correr con qiime (archivo qiime_ASV_process)

EVENTO: El Naive Bayes está desactualizado, con lo que entrenaremos un nuevo modelo usando los datos de Silva:

6. se entrena el modelo:
    dirección secuencias ya digeridas = https://data.qiime2.org/2021.4/common/silva-138-99-seqs.qza
    dirección taxonomía ya digerida = https://data.qiime2.org/2021.4/common/silva-138-99-tax.qza

    para entrenamiento del modelo:

        wget -O ref_seqs_naive_bayes_training.qza https://data.qiime2.org/2021.4/common/silva-138-99-seqs.qza
        wget -O ref_tax_naive_bayes_training.qza https://data.qiime2.org/2021.4/common/silva-138-99-tax.qza

        qiime feature-classifier fit-classifier-naive-bayes \
        --i-reference-reads ref_seqs_naive_bayes_training.qza \
        --i-reference-taxonomy ref_tax_naive_bayes_training.qza \
        --o-classifier naive_bayes_silva_6_5_2021.qza

7. planteo la posibilidad de realizar un análisis con OTUs en lugar de ASV (archivo qiime_OTU_process.sh)
El procedimiento es, a partir de los ASV que se generan en el denoising, clusterizarlos en este caso al 95,
sacar las estadísticas y tablas con normalidad